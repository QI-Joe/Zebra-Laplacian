{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from tgb.nodeproppred.dataset import NodePropPredDataset\n",
    "from tgb.nodeproppred.dataset_pyg import PyGNodePropPredDataset\n",
    "from tgb.nodeproppred.evaluate import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw file found, skipping download\n",
      "Dataset directory is  /home/joe/anaconda3/lib/python3.11/site-packages/tgb/data/tgbn_trade\n",
      "loading processed file\n",
      "raw file found, skipping download\n",
      "Dataset directory is  /home/joe/anaconda3/lib/python3.11/site-packages/tgb/data/tgbn_trade\n",
      "loading processed file\n"
     ]
    }
   ],
   "source": [
    "name = \"tgbn-trade\"\n",
    "dataset = NodePropPredDataset(name=name, root = r\"data/\", preprocess=True)\n",
    "data = dataset.full_data\n",
    "\n",
    "dataset_py = PyGNodePropPredDataset(name=name, root=r\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading processed file\n"
     ]
    }
   ],
   "source": [
    "df, node_label_dict, edge_feat = dataset.generate_processed_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.66176749e-05, 1.71066150e-04, 4.51711481e-04, 4.73375773e-05,\n",
       "       0.00000000e+00, 1.31982385e-04, 6.80742975e-06, 5.28580412e-03,\n",
       "       3.92755681e-04, 4.45800180e-03, 6.90175903e-05, 4.18193144e-06,\n",
       "       8.43571034e-03, 1.01393632e-01, 6.98250489e-03, 3.55187787e-02,\n",
       "       3.18078334e-04, 2.22475608e-04, 2.30559627e-03, 7.06714970e-04,\n",
       "       2.47887916e-03, 8.92382821e-02, 0.00000000e+00, 1.89020157e-04,\n",
       "       1.59501695e-02, 3.92299756e-04, 1.21008274e-02, 1.99166576e-01,\n",
       "       1.48254186e-05, 0.00000000e+00, 2.12555312e-05, 1.57215468e-06,\n",
       "       0.00000000e+00, 1.02954121e-03, 2.04851754e-05, 3.11286626e-05,\n",
       "       4.39561241e-02, 7.40380933e-02, 1.03799940e-03, 9.89317633e-03,\n",
       "       2.68653250e-02, 1.04395787e-03, 6.13140323e-07, 5.90092536e-03,\n",
       "       5.92702313e-06, 1.60491995e-02, 7.84347968e-05, 2.62392615e-05,\n",
       "       2.48970659e-02, 3.65060604e-03, 0.00000000e+00, 1.07378164e-05,\n",
       "       1.55512195e-02, 1.09437687e-04, 2.40228379e-03, 1.51874544e-02,\n",
       "       0.00000000e+00, 1.28460759e-04, 3.14745366e-05, 1.09736396e-05,\n",
       "       8.17834862e-05, 2.63568587e-03, 2.93521278e-05, 6.28861870e-08,\n",
       "       5.76980766e-06, 0.00000000e+00, 4.52151685e-05, 0.00000000e+00,\n",
       "       5.71949871e-05, 3.40582470e-02, 1.90485876e-02, 1.63032440e-05,\n",
       "       4.35172414e-05, 0.00000000e+00, 5.23527507e-06, 0.00000000e+00,\n",
       "       5.87985849e-06, 1.67009991e-04, 3.19304615e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 6.21158312e-05, 0.00000000e+00, 1.13195137e-06,\n",
       "       7.27168702e-04, 2.90282639e-04, 3.63703835e-03, 2.96414043e-04,\n",
       "       3.66719227e-03, 7.80810620e-04, 2.46828284e-06, 6.22573252e-06,\n",
       "       5.78552921e-05, 1.89051600e-03, 2.00292506e-05, 2.92625150e-04,\n",
       "       0.00000000e+00, 3.44366332e-03, 2.16273458e-03, 6.16284633e-06,\n",
       "       9.17981115e-05, 6.19218273e-03, 7.01574653e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 9.00630816e-03, 1.83784882e-05, 2.29838008e-03,\n",
       "       6.76026510e-07, 4.06401984e-04, 3.72600658e-06, 2.01937923e-02,\n",
       "       4.85324148e-05, 7.35139526e-05, 5.97418777e-07, 9.15638605e-04,\n",
       "       6.61216813e-04, 3.30411887e-03, 0.00000000e+00, 2.04537323e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.76362867e-06,\n",
       "       2.45256129e-06, 1.33947578e-05, 6.27604146e-05, 0.00000000e+00,\n",
       "       6.82566674e-04, 4.59069165e-06, 2.94779002e-05, 3.31724637e-06,\n",
       "       4.44762558e-05, 3.61595575e-07, 0.00000000e+00, 5.71588275e-04,\n",
       "       1.57215468e-08, 0.00000000e+00, 6.91119195e-05, 1.71364860e-06,\n",
       "       5.09378115e-06, 1.62089147e-05, 4.49085983e-04, 4.59069165e-06,\n",
       "       0.00000000e+00, 4.20912971e-04, 4.83280347e-04, 3.61595575e-07,\n",
       "       0.00000000e+00, 1.38632599e-04, 1.56724955e-03, 1.50675304e-04,\n",
       "       1.06302811e-03, 1.17428949e-03, 2.25918627e-05, 0.00000000e+00,\n",
       "       7.46216928e-03, 5.13308502e-05, 1.19483755e-05, 9.84326042e-05,\n",
       "       1.07503937e-04, 1.06906518e-06, 5.90768562e-04, 4.71646403e-08,\n",
       "       1.78958367e-04, 0.00000000e+00, 1.70264351e-05, 1.67683188e-02,\n",
       "       5.40978424e-04, 1.71347252e-02, 2.30477875e-05, 2.67266295e-06,\n",
       "       2.12555312e-05, 2.19630008e-05, 1.46839247e-05, 2.84559996e-06,\n",
       "       0.00000000e+00, 3.09400040e-05, 0.00000000e+00, 1.96519334e-06,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.03089496e-07,\n",
       "       0.00000000e+00, 1.72937014e-06, 9.27571259e-07, 1.25300728e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.01798885e-07,\n",
       "       2.67266295e-07, 0.00000000e+00, 0.00000000e+00, 3.61595575e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 6.52444190e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.36328292e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.71196682e-05, 0.00000000e+00, 6.28453110e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.88815777e-05, 1.83627666e-05, 1.77024616e-05, 1.19326540e-05,\n",
       "       2.03859725e-03, 1.08950319e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.39921766e-05, 2.19787224e-05, 4.77463375e-05, 3.00910405e-05,\n",
       "       1.82527158e-05, 2.49186516e-05, 4.82022624e-05, 2.62549831e-06,\n",
       "       6.35150489e-06, 2.33936616e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 3.30152482e-07, 3.06570162e-06, 9.43292805e-08,\n",
       "       3.14430935e-07, 0.00000000e+00, 0.00000000e+00, 2.21673809e-06,\n",
       "       2.33653628e-03, 1.53913943e-05, 1.96519334e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 9.78325128e-03, 0.00000000e+00,\n",
       "       5.06548236e-05, 0.00000000e+00, 1.36777457e-05, 2.23245964e-06,\n",
       "       0.00000000e+00, 2.20101655e-07, 0.00000000e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_label_dict[2016][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(name=name)\n",
    "metric = dataset.eval_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.unique(dataset.test_mask, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemporalData(src=[468245], dst=[468245], t=[468245], msg=[468245, 1], y=[468245])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_py = dataset_py.get_TemporalData()\n",
    "data_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([205, 255])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, label = dataset_py.get_node_label(1988)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemporalData(src=[468245], dst=[468245], t=[468245], msg=[468245, 1], y=[468245])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.vstack((data[\"sources\"], data[\"destinations\"]))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example shapes\n",
    "evaluator = Evaluator(name=\"tgbn-trade\")\n",
    "y_true = np.array([3, 2, 1, 0])  # True relevance scores\n",
    "y_pred = np.array([0.9, 0.8, 0.1, 0.0])  # Predicted scores\n",
    "\n",
    "eval_method = {\"y_pred\": y_pred, \n",
    "                       \"y_true\": y_true, \n",
    "                       \"eval_metric\": [\"rmse\"]}\n",
    "result = evaluator.eval(eval_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersistantForecaster:\n",
    "    def __init__(self, num_class):\n",
    "        self.dict = {}\n",
    "        self.num_class = num_class\n",
    "\n",
    "    def update_dict(self, node_id, label):\n",
    "        self.dict[node_id] = label\n",
    "\n",
    "    def query_dict(self, node_id):\n",
    "        r\"\"\"\n",
    "        Parameters:\n",
    "            node_id: the node to query\n",
    "        Returns:\n",
    "            returns the last seen label of the node if it exists, if not return zero vector\n",
    "        \"\"\"\n",
    "        if node_id in self.dict:\n",
    "            return self.dict[node_id]\n",
    "        else:\n",
    "            return np.zeros(self.num_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw file found, skipping download\n",
      "Dataset directory is  /home/joe/anaconda3/lib/python3.11/site-packages/tgb/datasets/tgbn_trade\n",
      "loading processed file\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "implement persistant forecast as baseline for the node prop pred task\n",
    "simply predict last seen label for the node\n",
    "\"\"\"\n",
    "\n",
    "import timeit\n",
    "import numpy as np\n",
    "from torch_geometric.loader import TemporalDataLoader\n",
    "\n",
    "# local imports\n",
    "from tgb.nodeproppred.dataset_pyg import PyGNodePropPredDataset\n",
    "from tgb.nodeproppred.evaluate import Evaluator\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "name = \"tgbn-trade\"\n",
    "dataset = PyGNodePropPredDataset(name=name, root=\"datasets\")\n",
    "num_classes = dataset.num_classes\n",
    "data = dataset.get_TemporalData()\n",
    "data = data.to(device)\n",
    "\n",
    "eval_metric = dataset.eval_metric\n",
    "forecaster = PersistantForecaster(num_classes)\n",
    "evaluator = Evaluator(name=name)\n",
    "\n",
    "\n",
    "# Ensure to only sample actual destination nodes as negatives.\n",
    "min_dst_idx, max_dst_idx = int(data.dst.min()), int(data.dst.max())\n",
    "train_data, val_data, test_data = data.train_val_test_split(\n",
    "    val_ratio=0.15, test_ratio=0.15\n",
    ")\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "train_loader = TemporalDataLoader(train_data, batch_size=batch_size)\n",
    "val_loader = TemporalDataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = TemporalDataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "\n",
    "def test_n_upate(loader):\n",
    "    label_t = dataset.get_label_time()  # check when does the first label start\n",
    "    num_label_ts = 0\n",
    "    total_score = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        src, pos_dst, t, msg = batch.src, batch.dst, batch.t, batch.msg\n",
    "\n",
    "        query_t = batch.t[-1]\n",
    "        if query_t > label_t:\n",
    "            label_tuple = dataset.get_node_label(query_t)\n",
    "            if label_tuple is None:\n",
    "                break\n",
    "            label_ts, label_srcs, labels = (\n",
    "                label_tuple[0],\n",
    "                label_tuple[1],\n",
    "                label_tuple[2],\n",
    "            )\n",
    "            label_ts = label_ts.numpy()\n",
    "            label_srcs = label_srcs.numpy()\n",
    "            labels = labels.numpy()\n",
    "            label_t = dataset.get_label_time()\n",
    "\n",
    "            preds = []\n",
    "\n",
    "            for i in range(0, label_srcs.shape[0]):\n",
    "                node_id = label_srcs[i]\n",
    "                pred_vec = forecaster.query_dict(node_id)\n",
    "                preds.append(pred_vec)\n",
    "                forecaster.update_dict(node_id, labels[i])\n",
    "\n",
    "            np_pred = np.stack(preds, axis=0)\n",
    "            np_true = labels\n",
    "\n",
    "            # print(np_true.shape, np_pred.shape)\n",
    "            input_dict = {\n",
    "                \"y_true\": np_true,\n",
    "                \"y_pred\": np_pred,\n",
    "                \"eval_metric\": [eval_metric],\n",
    "            }\n",
    "            result_dict = evaluator.eval(input_dict)\n",
    "            score = result_dict[eval_metric]\n",
    "            total_score += score\n",
    "            num_label_ts += 1\n",
    "\n",
    "    metric_dict = {}\n",
    "    metric_dict[eval_metric] = total_score / num_label_ts \n",
    "    return metric_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joe/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/mnt/d/CodingArea/Python/TPPR-Node-Classification\")\n",
    "from utils.data_processing import Data\n",
    "from utils.data_processing import TGB_load\n",
    "from utils.my_dataloader import position_encoding\n",
    "import numpy as np\n",
    "from tgb.nodeproppred.dataset import NodePropPredDataset\n",
    "from tgb.nodeproppred.dataset_pyg import PyGNodePropPredDataset\n",
    "from tgb.nodeproppred.evaluate import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw file found, skipping download\n",
      "Dataset directory is  /home/joe/anaconda3/lib/python3.11/site-packages/tgb/data/tgbn_genre\n",
      "loading processed file\n",
      "loading processed file\n"
     ]
    }
   ],
   "source": [
    "name = \"tgbn-genre\"\n",
    "\n",
    "dataset_py = PyGNodePropPredDataset(name=name, root=r\"data/\")\n",
    "\n",
    "df, node_label_dict, edge_feat = dataset_py.dataset.generate_processed_files()\n",
    "train_mask = dataset_py.train_mask\n",
    "val_mask = dataset_py.val_mask\n",
    "test_mask = dataset_py.test_mask\n",
    "data_py = dataset_py.get_TemporalData()\n",
    "\n",
    "train_data = data_py[train_mask]\n",
    "val_data = data_py[val_mask]\n",
    "test_data = data_py[test_mask]\n",
    "\n",
    "\n",
    "graph_num = max(data_py.src.max().item(), data_py.dst.max().item())\n",
    "edge_num = data_py.src.shape[0]\n",
    "\n",
    "graph_feat = position_encoding(graph_num, emb_size=64).numpy()\n",
    "train_data, val_data, test_data = TGB_load(train_data, val_data, test_data, graph_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_processor(data_label: dict[dict[int, np.ndarray]], data: Data)->list[tuple[np.ndarray]]:\n",
    "  time_stamp = data.timestamps\n",
    "  unique_ts = np.unique(time_stamp)\n",
    "  idx_list = np.arange(time_stamp.shape[0])\n",
    "  time_keys = list(data_label.keys())\n",
    "\n",
    "  last_idx = 0\n",
    "  batch_list: list[tuple] = list()\n",
    "  for ts in unique_ts:\n",
    "    time_mask = time_stamp==ts\n",
    "    # time_mask[:last_idx] = False\n",
    "    if ts not in time_keys:\n",
    "      # print(ts)\n",
    "      last_idx = idx_list[time_mask][-1]\n",
    "      continue\n",
    "\n",
    "    temp_dict = data_label[ts]\n",
    "    keys = np.array(list(temp_dict.keys()))\n",
    "    values = np.array(list(temp_dict.values()))\n",
    "\n",
    "    unique_time_nodes = set(data.sources[time_mask]) | set(data.destinations[time_mask])\n",
    "    if len(unique_time_nodes) != len(keys):\n",
    "      print(f\"At time {ts}; Under the same timetable the unique node {len(unique_time_nodes)} size and {len(set(keys))} isnt matched\")\n",
    "      print(f\"The different unique nodes are {unique_time_nodes - set(keys)} \\n\")\n",
    "\n",
    "    sort_idx = np.argsort(keys)\n",
    "    sort_key = keys[sort_idx]\n",
    "    values = values[sort_idx, :]\n",
    "    last_idx = idx_list[time_mask][-1]\n",
    "\n",
    "    backprop_mask = np.isin(np.array(sorted(unique_time_nodes)), sort_key)\n",
    "\n",
    "    batch_list.append((backprop_mask, values, time_mask))\n",
    "  print(\"process finshed\")\n",
    "  return batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = batch_processor(node_label_dict, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_key = len(node_label_dict.keys())\n",
    "time_stamp = train_data.timestamps\n",
    "unique_ts = np.unique(time_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1579 3061550\n"
     ]
    }
   ],
   "source": [
    "print(output_key, len(unique_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joe/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"../../Toy_data.csv\", encoding='latin1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
